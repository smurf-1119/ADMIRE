+ CHECKPOINT=/gruntdata/heyuan67/zqp/qp_lm_models/llamafactory/mpdocvqa_dude_newsvqa_slidevqa_448/full/sft_all/
+ DATASET=vqa-newsvqa-val-unsupervised-cls-v3-top5-test2
+ GPUS=8
+ CHECKPOINT=/gruntdata/heyuan67/zqp/qp_lm_models/llamafactory/mpdocvqa_dude_newsvqa_slidevqa_448/full/sft_all/
++ pwd
+ export PYTHONPATH=/mntnlp/zqp/physical_report/Qwen2-VL:/root/miniconda3/lib/python3.10/site-packages/aistudio_notebook/public:/root/miniconda3/lib/python3.10/site-packages/aistudio_notebook/public:/root/miniconda3/lib/python3.10/site-packages/aistudio_notebook/public:/root/miniconda3/lib/python3.10/site-packages/aistudio_notebook/public:/root/miniconda3/lib/python3.10/site-packages/aistudio_notebook/public:/root/miniconda3/lib/python3.10/site-packages/aistudio_notebook/public:/root/miniconda3/lib/python3.10/site-packages/aistudio_notebook/public:/root/miniconda3/lib/python3.10/site-packages/aistudio_notebook/public
+ PYTHONPATH=/mntnlp/zqp/physical_report/Qwen2-VL:/root/miniconda3/lib/python3.10/site-packages/aistudio_notebook/public:/root/miniconda3/lib/python3.10/site-packages/aistudio_notebook/public:/root/miniconda3/lib/python3.10/site-packages/aistudio_notebook/public:/root/miniconda3/lib/python3.10/site-packages/aistudio_notebook/public:/root/miniconda3/lib/python3.10/site-packages/aistudio_notebook/public:/root/miniconda3/lib/python3.10/site-packages/aistudio_notebook/public:/root/miniconda3/lib/python3.10/site-packages/aistudio_notebook/public:/root/miniconda3/lib/python3.10/site-packages/aistudio_notebook/public
+ echo 'CHECKPOINT: /gruntdata/heyuan67/zqp/qp_lm_models/llamafactory/mpdocvqa_dude_newsvqa_slidevqa_448/full/sft_all/'
CHECKPOINT: /gruntdata/heyuan67/zqp/qp_lm_models/llamafactory/mpdocvqa_dude_newsvqa_slidevqa_448/full/sft_all/
+ MASTER_PORT=36897
+ PORT=62621
+ GPUS=8
+ export MASTER_PORT=36897
+ MASTER_PORT=36897
+ export PORT=62621
+ PORT=62621
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-mpdocvqa-val ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-mpdocvqa-val-unsupervised-cls-v3-top3 ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-mpdocvqa-val-unsupervised-cls-v3-top3-test2 ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-mpdocvqa-val-unsupervised-cls-v3-top5 ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-mpdocvqa-val-unsupervised-cls-v3-top5-test2 ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-mpdocvqa-val-unsupervised-cls-v4-top3_mix ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-mpdocvqa-val-unsupervised-cls-v4-top3_mix-test2 ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-mpdocvqa-val-unsupervised-cls-v4-top5_mix ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-mpdocvqa-val-unsupervised-cls-v4-top5_mix-test2 ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-dude-mpdocvqa-val ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-dude-mpdocvqa-val-unsupervised-cls-v3-top3 ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-dude-mpdocvqa-val-unsupervised-cls-v3-top3-test2 ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-dude-mpdocvqa-val-unsupervised-cls-v3-top5 ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-dude-mpdocvqa-val-unsupervised-cls-v3-top5-test2 ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-dude-mpdocvqa-val-unsupervised-cls-v4-top3_mix ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-dude-mpdocvqa-val-unsupervised-cls-v4-top3_mix-test2 ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-dude-mpdocvqa-val-unsupervised-cls-v4-top5_mix ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-dude-mpdocvqa-val-unsupervised-cls-v4-top5_mix-test2 ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-newsvqa-val ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-newsvqa-val-unsupervised-cls-v3-top3 ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-newsvqa-val-unsupervised-cls-v3-top3-test2 ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-newsvqa-val-unsupervised-cls-v3-top5 ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 ']'
+ torchrun --nnodes=1 --node_rank=0 --master_addr=127.0.0.1 --nproc_per_node=8 --master_port=36897 infer_mpdocvqa_dynamic_unsupervised_cls3.py --checkpoint /gruntdata/heyuan67/zqp/qp_lm_models/llamafactory/mpdocvqa_dude_newsvqa_slidevqa_448/full/sft_all/ --max-pixels-low 200704 --max-pixels-high 40148 --datasets newsvqa_val --out-dir ./res/news-vqa --dynamic --select-mode topk --select-image-num 5
datasets: ['newsvqa_val']
datasets:datasets:  ['newsvqa_val']['newsvqa_val']

datasets: ['newsvqa_val']
datasets: ['newsvqa_val']
datasets: ['newsvqa_val']
datasets: ['newsvqa_val']
datasets: ['newsvqa_val']
Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  4.48it/s]Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46
Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}
Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46
`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46
Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}
Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46
`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46
Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  5.02it/s]Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour
`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46
`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  5.15it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  4.22it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  4.16it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  4.02it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  4.15it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  4.08it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.23it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.12it/s]
Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  4.72it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  3.44it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  3.25it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  4.70it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  4.56it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  4.69it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  4.60it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  4.38it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  4.88it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  3.89it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  4.86it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  4.72it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  4.83it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  4.74it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  4.72it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.02it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  4.89it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.01it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  4.87it/s]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  4.15it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  4.87it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  4.73it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  4.99it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  4.85it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  4.80it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  4.70it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  5.02it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  4.72it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  4.26it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  4.10it/s]
0it [00:00, ?it/s]0it [00:00, ?it/s]0it [00:00, ?it/s]0it [00:00, ?it/s]0it [00:00, ?it/s]0it [00:00, ?it/s]0it [00:00, ?it/s]0it [00:00, ?it/s]1it [00:02,  2.88s/it]1it [00:02,  2.96s/it]1it [00:02,  2.94s/it]1it [00:02,  2.83s/it]1it [00:02,  2.90s/it]1it [00:02,  2.93s/it]2it [00:04,  2.03s/it]2it [00:04,  2.07s/it]1it [00:02,  2.81s/it]2it [00:04,  2.04s/it]1it [00:03,  3.02s/it]2it [00:04,  1.98s/it]2it [00:04,  2.01s/it]2it [00:04,  2.04s/it]3it [00:05,  1.74s/it]3it [00:05,  1.77s/it]2it [00:04,  1.99s/it]3it [00:05,  1.76s/it]2it [00:04,  2.13s/it]3it [00:05,  1.75s/it]3it [00:05,  1.78s/it]3it [00:05,  1.76s/it]4it [00:07,  1.58s/it]4it [00:07,  1.63s/it]3it [00:05,  1.73s/it]4it [00:07,  1.62s/it]3it [00:05,  1.81s/it]4it [00:07,  1.63s/it]4it [00:07,  1.63s/it]4it [00:07,  1.66s/it]5it [00:08,  1.52s/it]5it [00:08,  1.55s/it]4it [00:07,  1.61s/it]5it [00:08,  1.56s/it]4it [00:07,  1.66s/it]5it [00:08,  1.57s/it]5it [00:08,  1.56s/it]5it [00:08,  1.57s/it]6it [00:09,  1.49s/it]6it [00:10,  1.49s/it]5it [00:08,  1.55s/it]6it [00:10,  1.53s/it]5it [00:08,  1.59s/it]6it [00:10,  1.51s/it]6it [00:10,  1.53s/it]6it [00:10,  1.55s/it]7it [00:11,  1.47s/it]7it [00:11,  1.47s/it]6it [00:09,  1.52s/it]7it [00:11,  1.63s/it]7it [00:11,  1.48s/it]7it [00:11,  1.49s/it]7it [00:11,  1.51s/it]6it [00:10,  1.63s/it]8it [00:12,  1.46s/it]8it [00:12,  1.44s/it]7it [00:11,  1.49s/it]8it [00:13,  1.56s/it]8it [00:12,  1.46s/it]8it [00:12,  1.48s/it]9it [00:14,  1.42s/it]8it [00:13,  1.48s/it]7it [00:12,  1.59s/it]9it [00:14,  1.42s/it]8it [00:12,  1.46s/it]9it [00:14,  1.50s/it]9it [00:14,  1.44s/it]9it [00:14,  1.47s/it]9it [00:14,  1.47s/it]10it [00:15,  1.45s/it]8it [00:13,  1.59s/it]10it [00:15,  1.43s/it]9it [00:14,  1.44s/it]10it [00:16,  1.48s/it]10it [00:15,  1.43s/it]10it [00:15,  1.46s/it]11it [00:16,  1.42s/it]10it [00:15,  1.48s/it]9it [00:15,  1.54s/it]11it [00:17,  1.47s/it]10it [00:15,  1.47s/it]11it [00:17,  1.45s/it]11it [00:17,  1.42s/it]12it [00:18,  1.41s/it]11it [00:17,  1.45s/it]11it [00:17,  1.46s/it]10it [00:16,  1.51s/it]12it [00:18,  1.45s/it]11it [00:17,  1.46s/it]12it [00:19,  1.47s/it]13it [00:19,  1.41s/it]12it [00:18,  1.46s/it]12it [00:18,  1.45s/it]12it [00:18,  1.47s/it]11it [00:17,  1.49s/it]13it [00:20,  1.45s/it]12it [00:18,  1.44s/it]13it [00:20,  1.45s/it]14it [00:21,  1.39s/it]13it [00:20,  1.45s/it]13it [00:20,  1.46s/it]13it [00:20,  1.45s/it]12it [00:19,  1.47s/it]14it [00:21,  1.43s/it]13it [00:20,  1.48s/it]14it [00:21,  1.47s/it]15it [00:22,  1.39s/it]14it [00:21,  1.40s/it]14it [00:21,  1.46s/it]14it [00:21,  1.44s/it]15it [00:22,  1.42s/it]13it [00:21,  1.51s/it]14it [00:21,  1.46s/it]15it [00:23,  1.45s/it]16it [00:23,  1.38s/it]15it [00:22,  1.35s/it]15it [00:22,  1.43s/it]15it [00:23,  1.46s/it]16it [00:24,  1.40s/it]14it [00:22,  1.53s/it]15it [00:23,  1.49s/it]16it [00:24,  1.32s/it]16it [00:24,  1.47s/it]17it [00:25,  1.40s/it]16it [00:24,  1.43s/it]16it [00:24,  1.44s/it]17it [00:25,  1.40s/it]15it [00:24,  1.54s/it]16it [00:24,  1.46s/it]17it [00:25,  1.34s/it]17it [00:26,  1.46s/it]18it [00:26,  1.44s/it]17it [00:25,  1.41s/it]17it [00:25,  1.43s/it]18it [00:27,  1.41s/it]18it [00:26,  1.31s/it]16it [00:25,  1.52s/it]17it [00:25,  1.45s/it]18it [00:27,  1.46s/it]19it [00:28,  1.43s/it]18it [00:27,  1.42s/it]18it [00:27,  1.43s/it]19it [00:28,  1.43s/it]19it [00:27,  1.28s/it]18it [00:27,  1.44s/it]17it [00:27,  1.51s/it]19it [00:29,  1.45s/it]20it [00:29,  1.42s/it]19it [00:28,  1.42s/it]19it [00:28,  1.43s/it]20it [00:29,  1.42s/it]20it [00:29,  1.28s/it]19it [00:28,  1.43s/it]18it [00:28,  1.53s/it]20it [00:30,  1.44s/it]21it [00:31,  1.41s/it]20it [00:29,  1.40s/it]20it [00:30,  1.42s/it]21it [00:30,  1.27s/it]21it [00:31,  1.44s/it]20it [00:30,  1.42s/it]19it [00:30,  1.51s/it]21it [00:32,  1.43s/it]22it [00:32,  1.42s/it]21it [00:31,  1.39s/it]21it [00:31,  1.43s/it]22it [00:31,  1.30s/it]22it [00:32,  1.45s/it]21it [00:31,  1.42s/it]22it [00:33,  1.42s/it]20it [00:31,  1.51s/it]23it [00:33,  1.43s/it]22it [00:32,  1.42s/it]22it [00:33,  1.45s/it]23it [00:33,  1.30s/it]23it [00:34,  1.44s/it]22it [00:32,  1.42s/it]23it [00:34,  1.43s/it]24it [00:35,  1.43s/it]23it [00:34,  1.41s/it]21it [00:33,  1.54s/it]24it [00:34,  1.28s/it]23it [00:34,  1.43s/it]24it [00:35,  1.43s/it]23it [00:34,  1.43s/it]24it [00:36,  1.43s/it]25it [00:36,  1.41s/it]25it [00:35,  1.28s/it]24it [00:35,  1.44s/it]22it [00:34,  1.51s/it]24it [00:35,  1.41s/it]25it [00:37,  1.43s/it]24it [00:35,  1.43s/it]26it [00:36,  1.28s/it]26it [00:38,  1.43s/it]25it [00:37,  1.48s/it]25it [00:37,  1.41s/it]23it [00:36,  1.49s/it]25it [00:37,  1.44s/it]26it [00:38,  1.43s/it]25it [00:37,  1.42s/it]27it [00:38,  1.26s/it]27it [00:39,  1.41s/it]26it [00:39,  1.47s/it]26it [00:38,  1.41s/it]26it [00:38,  1.44s/it]24it [00:37,  1.48s/it]27it [00:39,  1.41s/it]28it [00:39,  1.27s/it]26it [00:38,  1.42s/it]28it [00:40,  1.39s/it]25it [00:39,  1.46s/it]27it [00:40,  1.47s/it]27it [00:40,  1.44s/it]27it [00:40,  1.44s/it]28it [00:41,  1.40s/it]29it [00:40,  1.26s/it]27it [00:40,  1.44s/it]28it [00:41,  1.42s/it]28it [00:42,  1.46s/it]28it [00:41,  1.43s/it]26it [00:40,  1.46s/it]29it [00:42,  1.55s/it]29it [00:42,  1.41s/it]30it [00:41,  1.27s/it]28it [00:41,  1.44s/it]29it [00:42,  1.43s/it]27it [00:41,  1.46s/it]29it [00:43,  1.48s/it]29it [00:43,  1.45s/it]31it [00:43,  1.26s/it]30it [00:44,  1.40s/it]30it [00:44,  1.54s/it]29it [00:42,  1.42s/it]30it [00:44,  1.42s/it]32it [00:44,  1.27s/it]30it [00:44,  1.45s/it]30it [00:45,  1.48s/it]31it [00:45,  1.48s/it]28it [00:43,  1.50s/it]31it [00:45,  1.41s/it]30it [00:44,  1.42s/it]33it [00:45,  1.28s/it]31it [00:45,  1.44s/it]31it [00:45,  1.45s/it]31it [00:46,  1.46s/it]32it [00:47,  1.47s/it]32it [00:46,  1.41s/it]29it [00:45,  1.54s/it]31it [00:45,  1.42s/it]34it [00:47,  1.32s/it]32it [00:47,  1.43s/it]32it [00:48,  1.44s/it]32it [00:47,  1.44s/it]33it [00:48,  1.40s/it]33it [00:48,  1.48s/it]30it [00:46,  1.53s/it]32it [00:47,  1.46s/it]35it [00:48,  1.35s/it]33it [00:48,  1.42s/it]33it [00:48,  1.44s/it]33it [00:49,  1.45s/it]34it [00:49,  1.41s/it]34it [00:49,  1.45s/it]31it [00:48,  1.54s/it]33it [00:48,  1.46s/it]36it [00:49,  1.37s/it]34it [00:49,  1.41s/it]34it [00:50,  1.43s/it]35it [00:51,  1.43s/it]34it [00:51,  1.45s/it]35it [00:51,  1.43s/it]32it [00:49,  1.50s/it]34it [00:50,  1.45s/it]37it [00:51,  1.39s/it]35it [00:51,  1.42s/it]35it [00:51,  1.42s/it]35it [00:52,  1.44s/it]36it [00:52,  1.44s/it]36it [00:52,  1.44s/it]33it [00:51,  1.47s/it]35it [00:51,  1.43s/it]36it [00:52,  1.42s/it]38it [00:52,  1.41s/it]36it [00:52,  1.42s/it]37it [00:54,  1.42s/it]36it [00:53,  1.45s/it]37it [00:54,  1.42s/it]34it [00:52,  1.45s/it]36it [00:53,  1.42s/it]37it [00:54,  1.43s/it]39it [00:54,  1.42s/it]37it [00:54,  1.42s/it]38it [00:55,  1.41s/it]38it [00:55,  1.42s/it]37it [00:55,  1.45s/it]35it [00:53,  1.46s/it]37it [00:54,  1.41s/it]40it [00:55,  1.43s/it]38it [00:55,  1.43s/it]39it [00:56,  1.40s/it]38it [00:55,  1.48s/it]39it [00:56,  1.42s/it]38it [00:56,  1.45s/it]36it [00:55,  1.46s/it]38it [00:55,  1.41s/it]41it [00:57,  1.44s/it]39it [00:57,  1.42s/it]39it [00:57,  1.48s/it]40it [00:58,  1.44s/it]40it [00:58,  1.43s/it]39it [00:58,  1.46s/it]37it [00:56,  1.47s/it]39it [00:57,  1.43s/it]42it [00:58,  1.43s/it]40it [00:58,  1.42s/it]41it [00:59,  1.43s/it]41it [00:59,  1.42s/it]40it [00:58,  1.48s/it]40it [00:59,  1.45s/it]38it [00:58,  1.45s/it]40it [00:58,  1.43s/it]43it [01:00,  1.43s/it]41it [01:00,  1.42s/it]42it [01:01,  1.42s/it]42it [01:01,  1.43s/it]41it [01:00,  1.46s/it]41it [01:01,  1.45s/it]39it [00:59,  1.45s/it]41it [01:00,  1.42s/it]44it [01:01,  1.42s/it]42it [01:01,  1.41s/it]43it [01:02,  1.41s/it]42it [01:01,  1.44s/it]43it [01:02,  1.46s/it]42it [01:02,  1.45s/it]40it [01:01,  1.46s/it]42it [01:01,  1.43s/it]45it [01:02,  1.42s/it]43it [01:02,  1.43s/it]44it [01:03,  1.40s/it]43it [01:03,  1.44s/it]44it [01:04,  1.43s/it]43it [01:04,  1.46s/it]41it [01:02,  1.45s/it]43it [01:03,  1.44s/it]46it [01:04,  1.42s/it]44it [01:04,  1.44s/it]45it [01:05,  1.41s/it]45it [01:05,  1.41s/it]44it [01:04,  1.43s/it]44it [01:05,  1.47s/it]42it [01:04,  1.43s/it]44it [01:04,  1.43s/it]47it [01:05,  1.41s/it]45it [01:05,  1.44s/it]46it [01:06,  1.41s/it]46it [01:06,  1.43s/it]45it [01:05,  1.43s/it]45it [01:06,  1.45s/it]43it [01:05,  1.44s/it]45it [01:05,  1.43s/it]48it [01:07,  1.41s/it]47it [01:08,  1.41s/it]46it [01:07,  1.44s/it]47it [01:08,  1.42s/it]46it [01:07,  1.45s/it]46it [01:08,  1.45s/it]44it [01:06,  1.45s/it]46it [01:07,  1.44s/it]49it [01:08,  1.43s/it]48it [01:09,  1.39s/it]48it [01:09,  1.41s/it]47it [01:08,  1.46s/it]47it [01:08,  1.43s/it]47it [01:09,  1.43s/it]45it [01:08,  1.44s/it]47it [01:08,  1.44s/it]49it [01:11,  1.39s/it]50it [01:10,  1.48s/it]49it [01:11,  1.43s/it]48it [01:10,  1.45s/it]48it [01:10,  1.43s/it]48it [01:11,  1.44s/it]46it [01:09,  1.43s/it]48it [01:10,  1.43s/it]50it [01:12,  1.39s/it]50it [01:12,  1.42s/it]49it [01:11,  1.43s/it]51it [01:11,  1.47s/it]49it [01:11,  1.45s/it]49it [01:12,  1.43s/it]47it [01:11,  1.43s/it]49it [01:11,  1.42s/it]51it [01:13,  1.37s/it]50it [01:13,  1.44s/it]51it [01:14,  1.44s/it]52it [01:13,  1.47s/it]50it [01:13,  1.44s/it]50it [01:14,  1.43s/it]48it [01:12,  1.45s/it]50it [01:13,  1.45s/it]52it [01:15,  1.37s/it]52it [01:15,  1.43s/it]51it [01:14,  1.44s/it]53it [01:14,  1.46s/it]51it [01:14,  1.44s/it]51it [01:15,  1.41s/it]49it [01:14,  1.45s/it]51it [01:14,  1.45s/it]53it [01:16,  1.37s/it]53it [01:16,  1.42s/it]52it [01:15,  1.43s/it]54it [01:16,  1.48s/it]52it [01:16,  1.46s/it]52it [01:16,  1.41s/it]50it [01:15,  1.45s/it]52it [01:16,  1.45s/it]54it [01:17,  1.36s/it]54it [01:18,  1.41s/it]53it [01:17,  1.42s/it]55it [01:17,  1.47s/it]53it [01:18,  1.41s/it]53it [01:17,  1.45s/it]51it [01:17,  1.46s/it]55it [01:19,  1.37s/it]53it [01:17,  1.47s/it]55it [01:19,  1.43s/it]54it [01:18,  1.47s/it]54it [01:19,  1.41s/it]54it [01:18,  1.44s/it]56it [01:19,  1.49s/it]56it [01:20,  1.36s/it]52it [01:18,  1.46s/it]54it [01:19,  1.47s/it]56it [01:21,  1.44s/it]55it [01:20,  1.46s/it]55it [01:21,  1.42s/it]55it [01:20,  1.45s/it]57it [01:20,  1.47s/it]57it [01:22,  1.36s/it]53it [01:20,  1.46s/it]55it [01:20,  1.47s/it]57it [01:22,  1.43s/it]56it [01:22,  1.41s/it]58it [01:21,  1.45s/it]56it [01:21,  1.46s/it]56it [01:21,  1.52s/it]58it [01:23,  1.37s/it]54it [01:21,  1.45s/it]56it [01:21,  1.45s/it]58it [01:23,  1.41s/it]57it [01:23,  1.41s/it]59it [01:23,  1.45s/it]57it [01:23,  1.50s/it]57it [01:23,  1.50s/it]59it [01:24,  1.38s/it]55it [01:22,  1.45s/it]57it [01:23,  1.45s/it]59it [01:25,  1.42s/it]58it [01:25,  1.41s/it]60it [01:24,  1.43s/it]58it [01:24,  1.47s/it]58it [01:24,  1.47s/it]60it [01:26,  1.37s/it]56it [01:24,  1.46s/it]58it [01:24,  1.47s/it]60it [01:26,  1.44s/it]59it [01:26,  1.43s/it]61it [01:26,  1.42s/it]59it [01:26,  1.47s/it]59it [01:26,  1.45s/it]61it [01:27,  1.38s/it]57it [01:25,  1.45s/it]59it [01:26,  1.47s/it]61it [01:28,  1.43s/it]60it [01:28,  1.44s/it]62it [01:27,  1.42s/it]60it [01:27,  1.46s/it]60it [01:27,  1.46s/it]62it [01:28,  1.36s/it]58it [01:27,  1.45s/it]60it [01:27,  1.45s/it]62it [01:29,  1.43s/it]61it [01:29,  1.44s/it]63it [01:29,  1.45s/it]63it [01:30,  1.35s/it]61it [01:29,  1.44s/it]61it [01:29,  1.46s/it]59it [01:28,  1.45s/it]61it [01:29,  1.44s/it]63it [01:31,  1.48s/it]64it [01:30,  1.43s/it]62it [01:31,  1.46s/it]64it [01:31,  1.35s/it]62it [01:30,  1.49s/it]62it [01:30,  1.50s/it]60it [01:30,  1.46s/it]62it [01:30,  1.43s/it]63it [01:32,  1.43s/it]65it [01:33,  1.38s/it]65it [01:31,  1.46s/it]64it [01:32,  1.53s/it]63it [01:32,  1.48s/it]63it [01:32,  1.52s/it]61it [01:31,  1.46s/it]63it [01:31,  1.42s/it]64it [01:33,  1.41s/it]66it [01:34,  1.39s/it]66it [01:33,  1.45s/it]65it [01:34,  1.50s/it]64it [01:33,  1.46s/it]64it [01:33,  1.51s/it]64it [01:33,  1.42s/it]62it [01:33,  1.47s/it]65it [01:35,  1.41s/it]67it [01:35,  1.40s/it]66it [01:35,  1.46s/it]67it [01:34,  1.44s/it]65it [01:35,  1.46s/it]65it [01:35,  1.51s/it]65it [01:34,  1.41s/it]63it [01:34,  1.47s/it]66it [01:36,  1.41s/it]68it [01:37,  1.38s/it]67it [01:37,  1.43s/it]68it [01:36,  1.45s/it]66it [01:36,  1.45s/it]66it [01:36,  1.47s/it]66it [01:36,  1.41s/it]64it [01:36,  1.46s/it]67it [01:38,  1.41s/it]69it [01:38,  1.37s/it]68it [01:38,  1.41s/it]69it [01:37,  1.43s/it]67it [01:37,  1.45s/it]67it [01:38,  1.45s/it]67it [01:37,  1.42s/it]65it [01:37,  1.47s/it]70it [01:39,  1.36s/it]68it [01:39,  1.41s/it]69it [01:39,  1.41s/it]70it [01:39,  1.43s/it]68it [01:39,  1.43s/it]68it [01:39,  1.46s/it]68it [01:39,  1.42s/it]66it [01:38,  1.47s/it]71it [01:41,  1.35s/it]69it [01:40,  1.40s/it]70it [01:41,  1.44s/it]71it [01:40,  1.43s/it]69it [01:40,  1.41s/it]69it [01:40,  1.44s/it]69it [01:40,  1.42s/it]72it [01:42,  1.36s/it]67it [01:40,  1.49s/it]70it [01:42,  1.41s/it]71it [01:42,  1.46s/it]72it [01:41,  1.43s/it]70it [01:42,  1.41s/it]70it [01:42,  1.39s/it]70it [01:41,  1.43s/it]73it [01:43,  1.36s/it]68it [01:41,  1.48s/it]71it [01:43,  1.41s/it]72it [01:44,  1.44s/it]73it [01:43,  1.43s/it]71it [01:43,  1.43s/it]71it [01:43,  1.38s/it]71it [01:43,  1.43s/it]74it [01:45,  1.36s/it]72it [01:45,  1.41s/it]69it [01:43,  1.47s/it]73it [01:45,  1.44s/it]72it [01:44,  1.33s/it]74it [01:44,  1.46s/it]72it [01:44,  1.41s/it]75it [01:46,  1.36s/it]72it [01:44,  1.48s/it]73it [01:46,  1.41s/it]70it [01:44,  1.47s/it]73it [01:46,  1.30s/it]74it [01:47,  1.44s/it]73it [01:46,  1.40s/it]75it [01:46,  1.49s/it]76it [01:48,  1.36s/it]73it [01:46,  1.49s/it]74it [01:48,  1.40s/it]74it [01:47,  1.28s/it]71it [01:46,  1.45s/it]75it [01:48,  1.43s/it]74it [01:47,  1.40s/it]76it [01:47,  1.47s/it]77it [01:49,  1.36s/it]75it [01:48,  1.30s/it]75it [01:49,  1.41s/it]74it [01:48,  1.52s/it]72it [01:47,  1.45s/it]76it [01:49,  1.43s/it]75it [01:49,  1.41s/it]77it [01:49,  1.44s/it]78it [01:50,  1.37s/it]76it [01:49,  1.28s/it]76it [01:50,  1.41s/it]73it [01:49,  1.44s/it]75it [01:49,  1.51s/it]77it [01:51,  1.42s/it]76it [01:50,  1.40s/it]78it [01:50,  1.43s/it]79it [01:52,  1.36s/it]77it [01:51,  1.26s/it]77it [01:52,  1.43s/it]74it [01:50,  1.45s/it]76it [01:51,  1.51s/it]78it [01:52,  1.45s/it]77it [01:52,  1.41s/it]79it [01:52,  1.44s/it]80it [01:53,  1.36s/it]78it [01:52,  1.26s/it]78it [01:53,  1.45s/it]75it [01:52,  1.45s/it]77it [01:52,  1.50s/it]78it [01:53,  1.41s/it]79it [01:54,  1.47s/it]80it [01:53,  1.45s/it]79it [01:53,  1.26s/it]81it [01:54,  1.35s/it]79it [01:55,  1.44s/it]76it [01:53,  1.46s/it]80it [01:54,  1.25s/it]80it [01:55,  1.45s/it]78it [01:54,  1.53s/it]79it [01:54,  1.44s/it]81it [01:54,  1.43s/it]82it [01:56,  1.37s/it]80it [01:56,  1.45s/it]77it [01:55,  1.47s/it]81it [01:57,  1.45s/it]81it [01:56,  1.31s/it]79it [01:55,  1.52s/it]80it [01:56,  1.44s/it]83it [01:57,  1.35s/it]82it [01:56,  1.43s/it]81it [01:58,  1.44s/it]78it [01:56,  1.47s/it]82it [01:57,  1.30s/it]82it [01:58,  1.44s/it]81it [01:57,  1.43s/it]84it [01:58,  1.36s/it]83it [01:57,  1.44s/it]80it [01:57,  1.54s/it]82it [01:59,  1.45s/it]83it [01:58,  1.32s/it]79it [01:58,  1.47s/it]85it [02:00,  1.37s/it]82it [01:59,  1.43s/it]84it [01:59,  1.44s/it]81it [01:58,  1.51s/it]83it [02:00,  1.51s/it]83it [02:01,  1.44s/it]84it [02:00,  1.32s/it]80it [01:59,  1.46s/it]86it [02:01,  1.36s/it]83it [02:00,  1.43s/it]85it [02:00,  1.44s/it]82it [02:00,  1.49s/it]84it [02:01,  1.49s/it]85it [02:01,  1.30s/it]84it [02:02,  1.45s/it]87it [02:02,  1.35s/it]81it [02:00,  1.46s/it]84it [02:02,  1.42s/it]86it [02:02,  1.44s/it]85it [02:03,  1.48s/it]83it [02:01,  1.54s/it]86it [02:02,  1.27s/it]88it [02:04,  1.34s/it]85it [02:03,  1.44s/it]82it [02:02,  1.45s/it]85it [02:03,  1.47s/it]87it [02:03,  1.45s/it]86it [02:04,  1.45s/it]84it [02:03,  1.51s/it]87it [02:04,  1.28s/it]89it [02:05,  1.35s/it]89it [02:05,  1.41s/it]
86it [02:05,  1.44s/it]83it [02:03,  1.46s/it]86it [02:05,  1.45s/it]87it [02:06,  1.45s/it]88it [02:05,  1.45s/it]88it [02:05,  1.29s/it]85it [02:04,  1.52s/it]87it [02:06,  1.43s/it]84it [02:05,  1.44s/it]87it [02:06,  1.47s/it]88it [02:07,  1.44s/it]89it [02:06,  1.46s/it]89it [02:06,  1.29s/it]89it [02:06,  1.42s/it]
89it [02:06,  1.42s/it]
86it [02:06,  1.50s/it]88it [02:08,  1.41s/it]85it [02:06,  1.44s/it]89it [02:08,  1.43s/it]88it [02:07,  1.45s/it]89it [02:08,  1.45s/it]
87it [02:07,  1.46s/it]89it [02:09,  1.40s/it]89it [02:09,  1.46s/it]
86it [02:08,  1.43s/it]89it [02:09,  1.43s/it]89it [02:09,  1.45s/it]
88it [02:08,  1.45s/it]87it [02:09,  1.50s/it]89it [02:10,  1.43s/it]89it [02:10,  1.47s/it]
88it [02:11,  1.47s/it]89it [02:12,  1.47s/it]89it [02:12,  1.49s/it]
[rank4]: Traceback (most recent call last):
[rank4]:   File "/mntnlp/zqp/physical_report/Qwen2-VL/infer_mpdocvqa_dynamic_unsupervised_cls3.py", line 575, in <module>
[rank4]:     evaluate_chat_model(model, processor, image_process_args, args.select_mode, args.select_image_num)
[rank4]:   File "/mntnlp/zqp/physical_report/Qwen2-VL/infer_mpdocvqa_dynamic_unsupervised_cls3.py", line 447, in evaluate_chat_model
[rank4]:     torch.distributed.all_gather_object(merged_avg_vtokens, json.dumps(avg_vtokens_list))
[rank4]:   File "/root/miniconda3/lib/python3.10/json/__init__.py", line 231, in dumps
[rank4]:     return _default_encoder.encode(obj)
[rank4]:   File "/root/miniconda3/lib/python3.10/json/encoder.py", line 199, in encode
[rank4]:     chunks = self.iterencode(o, _one_shot=True)
[rank4]:   File "/root/miniconda3/lib/python3.10/json/encoder.py", line 257, in iterencode
[rank4]:     return _iterencode(o, 0)
[rank4]:   File "/root/miniconda3/lib/python3.10/json/encoder.py", line 179, in default
[rank4]:     raise TypeError(f'Object of type {o.__class__.__name__} '
[rank4]: TypeError: Object of type Tensor is not JSON serializable
[rank7]: Traceback (most recent call last):
[rank7]:   File "/mntnlp/zqp/physical_report/Qwen2-VL/infer_mpdocvqa_dynamic_unsupervised_cls3.py", line 575, in <module>
[rank7]:     evaluate_chat_model(model, processor, image_process_args, args.select_mode, args.select_image_num)
[rank7]:   File "/mntnlp/zqp/physical_report/Qwen2-VL/infer_mpdocvqa_dynamic_unsupervised_cls3.py", line 447, in evaluate_chat_model
[rank7]:     torch.distributed.all_gather_object(merged_avg_vtokens, json.dumps(avg_vtokens_list))
[rank7]:   File "/root/miniconda3/lib/python3.10/json/__init__.py", line 231, in dumps
[rank7]:     return _default_encoder.encode(obj)
[rank7]:   File "/root/miniconda3/lib/python3.10/json/encoder.py", line 199, in encode
[rank7]:     chunks = self.iterencode(o, _one_shot=True)
[rank7]:   File "/root/miniconda3/lib/python3.10/json/encoder.py", line 257, in iterencode
[rank7]:     return _iterencode(o, 0)
[rank7]:   File "/root/miniconda3/lib/python3.10/json/encoder.py", line 179, in default
[rank7]:     raise TypeError(f'Object of type {o.__class__.__name__} '
[rank7]: TypeError: Object of type Tensor is not JSON serializable
[rank6]: Traceback (most recent call last):
[rank6]:   File "/mntnlp/zqp/physical_report/Qwen2-VL/infer_mpdocvqa_dynamic_unsupervised_cls3.py", line 575, in <module>
[rank6]:     evaluate_chat_model(model, processor, image_process_args, args.select_mode, args.select_image_num)
[rank6]:   File "/mntnlp/zqp/physical_report/Qwen2-VL/infer_mpdocvqa_dynamic_unsupervised_cls3.py", line 447, in evaluate_chat_model
[rank6]:     torch.distributed.all_gather_object(merged_avg_vtokens, json.dumps(avg_vtokens_list))
[rank6]:   File "/root/miniconda3/lib/python3.10/json/__init__.py", line 231, in dumps
[rank6]:     return _default_encoder.encode(obj)
[rank6]:   File "/root/miniconda3/lib/python3.10/json/encoder.py", line 199, in encode
[rank6]:     chunks = self.iterencode(o, _one_shot=True)
[rank6]:   File "/root/miniconda3/lib/python3.10/json/encoder.py", line 257, in iterencode
[rank6]:     return _iterencode(o, 0)
[rank6]:   File "/root/miniconda3/lib/python3.10/json/encoder.py", line 179, in default
[rank6]:     raise TypeError(f'Object of type {o.__class__.__name__} '
[rank6]: TypeError: Object of type Tensor is not JSON serializable
[rank5]: Traceback (most recent call last):
[rank5]:   File "/mntnlp/zqp/physical_report/Qwen2-VL/infer_mpdocvqa_dynamic_unsupervised_cls3.py", line 575, in <module>
[rank5]:     evaluate_chat_model(model, processor, image_process_args, args.select_mode, args.select_image_num)
[rank5]:   File "/mntnlp/zqp/physical_report/Qwen2-VL/infer_mpdocvqa_dynamic_unsupervised_cls3.py", line 447, in evaluate_chat_model
[rank5]:     torch.distributed.all_gather_object(merged_avg_vtokens, json.dumps(avg_vtokens_list))
[rank5]:   File "/root/miniconda3/lib/python3.10/json/__init__.py", line 231, in dumps
[rank5]:     return _default_encoder.encode(obj)
[rank5]:   File "/root/miniconda3/lib/python3.10/json/encoder.py", line 199, in encode
[rank5]:     chunks = self.iterencode(o, _one_shot=True)
[rank5]:   File "/root/miniconda3/lib/python3.10/json/encoder.py", line 257, in iterencode
[rank5]:     return _iterencode(o, 0)
[rank5]:   File "/root/miniconda3/lib/python3.10/json/encoder.py", line 179, in default
[rank5]:     raise TypeError(f'Object of type {o.__class__.__name__} '
[rank5]: TypeError: Object of type Tensor is not JSON serializable
[rank3]: Traceback (most recent call last):
[rank3]:   File "/mntnlp/zqp/physical_report/Qwen2-VL/infer_mpdocvqa_dynamic_unsupervised_cls3.py", line 575, in <module>
[rank3]:     evaluate_chat_model(model, processor, image_process_args, args.select_mode, args.select_image_num)
[rank3]:   File "/mntnlp/zqp/physical_report/Qwen2-VL/infer_mpdocvqa_dynamic_unsupervised_cls3.py", line 447, in evaluate_chat_model
[rank3]:     torch.distributed.all_gather_object(merged_avg_vtokens, json.dumps(avg_vtokens_list))
[rank3]:   File "/root/miniconda3/lib/python3.10/json/__init__.py", line 231, in dumps
[rank3]:     return _default_encoder.encode(obj)
[rank3]:   File "/root/miniconda3/lib/python3.10/json/encoder.py", line 199, in encode
[rank3]:     chunks = self.iterencode(o, _one_shot=True)
[rank3]:   File "/root/miniconda3/lib/python3.10/json/encoder.py", line 257, in iterencode
[rank3]:     return _iterencode(o, 0)
[rank3]:   File "/root/miniconda3/lib/python3.10/json/encoder.py", line 179, in default
[rank3]:     raise TypeError(f'Object of type {o.__class__.__name__} '
[rank3]: TypeError: Object of type Tensor is not JSON serializable
[rank1]: Traceback (most recent call last):
[rank1]:   File "/mntnlp/zqp/physical_report/Qwen2-VL/infer_mpdocvqa_dynamic_unsupervised_cls3.py", line 575, in <module>
[rank1]:     evaluate_chat_model(model, processor, image_process_args, args.select_mode, args.select_image_num)
[rank1]:   File "/mntnlp/zqp/physical_report/Qwen2-VL/infer_mpdocvqa_dynamic_unsupervised_cls3.py", line 447, in evaluate_chat_model
[rank1]:     torch.distributed.all_gather_object(merged_avg_vtokens, json.dumps(avg_vtokens_list))
[rank1]:   File "/root/miniconda3/lib/python3.10/json/__init__.py", line 231, in dumps
[rank1]:     return _default_encoder.encode(obj)
[rank1]:   File "/root/miniconda3/lib/python3.10/json/encoder.py", line 199, in encode
[rank1]:     chunks = self.iterencode(o, _one_shot=True)
[rank1]:   File "/root/miniconda3/lib/python3.10/json/encoder.py", line 257, in iterencode
[rank1]:     return _iterencode(o, 0)
[rank1]:   File "/root/miniconda3/lib/python3.10/json/encoder.py", line 179, in default
[rank1]:     raise TypeError(f'Object of type {o.__class__.__name__} '
[rank1]: TypeError: Object of type Tensor is not JSON serializable
[rank0]: Traceback (most recent call last):
[rank0]:   File "/mntnlp/zqp/physical_report/Qwen2-VL/infer_mpdocvqa_dynamic_unsupervised_cls3.py", line 575, in <module>
[rank0]:     evaluate_chat_model(model, processor, image_process_args, args.select_mode, args.select_image_num)
[rank0]:   File "/mntnlp/zqp/physical_report/Qwen2-VL/infer_mpdocvqa_dynamic_unsupervised_cls3.py", line 447, in evaluate_chat_model
[rank0]:     torch.distributed.all_gather_object(merged_avg_vtokens, json.dumps(avg_vtokens_list))
[rank0]:   File "/root/miniconda3/lib/python3.10/json/__init__.py", line 231, in dumps
[rank0]:     return _default_encoder.encode(obj)
[rank0]:   File "/root/miniconda3/lib/python3.10/json/encoder.py", line 199, in encode
[rank0]:     chunks = self.iterencode(o, _one_shot=True)
[rank0]:   File "/root/miniconda3/lib/python3.10/json/encoder.py", line 257, in iterencode
[rank0]:     return _iterencode(o, 0)
[rank0]:   File "/root/miniconda3/lib/python3.10/json/encoder.py", line 179, in default
[rank0]:     raise TypeError(f'Object of type {o.__class__.__name__} '
[rank0]: TypeError: Object of type Tensor is not JSON serializable
[rank2]: Traceback (most recent call last):
[rank2]:   File "/mntnlp/zqp/physical_report/Qwen2-VL/infer_mpdocvqa_dynamic_unsupervised_cls3.py", line 575, in <module>
[rank2]:     evaluate_chat_model(model, processor, image_process_args, args.select_mode, args.select_image_num)
[rank2]:   File "/mntnlp/zqp/physical_report/Qwen2-VL/infer_mpdocvqa_dynamic_unsupervised_cls3.py", line 447, in evaluate_chat_model
[rank2]:     torch.distributed.all_gather_object(merged_avg_vtokens, json.dumps(avg_vtokens_list))
[rank2]:   File "/root/miniconda3/lib/python3.10/json/__init__.py", line 231, in dumps
[rank2]:     return _default_encoder.encode(obj)
[rank2]:   File "/root/miniconda3/lib/python3.10/json/encoder.py", line 199, in encode
[rank2]:     chunks = self.iterencode(o, _one_shot=True)
[rank2]:   File "/root/miniconda3/lib/python3.10/json/encoder.py", line 257, in iterencode
[rank2]:     return _iterencode(o, 0)
[rank2]:   File "/root/miniconda3/lib/python3.10/json/encoder.py", line 179, in default
[rank2]:     raise TypeError(f'Object of type {o.__class__.__name__} '
[rank2]: TypeError: Object of type Tensor is not JSON serializable
W1222 09:15:46.647000 140214229183360 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 199370 closing signal SIGTERM
W1222 09:15:46.648000 140214229183360 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 199372 closing signal SIGTERM
W1222 09:15:46.648000 140214229183360 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 199373 closing signal SIGTERM
W1222 09:15:46.648000 140214229183360 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 199374 closing signal SIGTERM
W1222 09:15:46.648000 140214229183360 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 199375 closing signal SIGTERM
W1222 09:15:46.648000 140214229183360 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 199376 closing signal SIGTERM
W1222 09:15:46.648000 140214229183360 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 199377 closing signal SIGTERM
E1222 09:15:47.765000 140214229183360 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 1 (pid: 199371) of binary: /root/miniconda3/bin/python
Traceback (most recent call last):
  File "/root/miniconda3/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/root/miniconda3/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/root/miniconda3/lib/python3.10/site-packages/zhenjin_utils/import_hooks/torchrun_args_hook.py", line 28, in new_run
    return module.old_run(*func_args, **func_kwargs)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/root/miniconda3/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/root/miniconda3/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
infer_mpdocvqa_dynamic_unsupervised_cls3.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-12-22_09:15:46
  host      : amed-kmaker-033145117225
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 199371)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-newsvqa-val-unsupervised-cls-v4-top3_mix ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-newsvqa-val-unsupervised-cls-v4-top3_mix-test2 ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-newsvqa-val-unsupervised-cls-v4-top5_mix ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-newsvqa-val-unsupervised-cls-v4-top5_mix-test2 ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-slidevqa-val ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-slidevqa-val-unsupervised-cls-v3-top3 ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-slidevqa-val-unsupervised-cls-v3-top3-test2 ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-slidevqa-val-unsupervised-cls-v3-top5 ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-slidevqa-val-unsupervised-cls-v3-top5-test2 ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-slidevqa-val-unsupervised-cls-v4-top3_mix ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-slidevqa-val-unsupervised-cls-v4-top3_mix-test2 ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-slidevqa-val-unsupervised-cls-v4-top5_mix ']'
+ '[' vqa-newsvqa-val-unsupervised-cls-v3-top5-test2 == vqa-slidevqa-val-unsupervised-cls-v4-top5_mix-test2 ']'
